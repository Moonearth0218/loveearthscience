import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import io
import plotly.express as px

# --------------------
# ê¸°ë³¸ ì„¤ì •
# --------------------
st.set_page_config(page_title="ğŸ—ºï¸ ì „ì„¸ê³„ ì§€ì§„ ê·œëª¨", page_icon="ğŸ—ºï¸", layout="wide")
st.title("ğŸ—ºï¸ ì „ì„¸ê³„ ì§€ì§„ ê·œëª¨ ë¶„ì„")
st.caption("KMA êµ­ì™¸ì§€ì§„ëª©ë¡ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ê·œëª¨(M) ì •ìˆ˜ êµ¬ê°„ë³„ ìƒ‰ìƒìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.")

DEFAULT_FILE = "êµ­ì™¸ì§€ì§„ëª©ë¡_2015-01-01_2025-09-29.xls"

# ---------- ìƒˆ ë¡œë”: í˜•ì‹ ìë™ ë¶„ê¸° ----------
@st.cache_data(show_spinner=False)
def load_quakes(file_bytes: bytes, filename: str = "uploaded") -> pd.DataFrame:
    """
    ì—…ë¡œë“œëœ ë°”ì´íŠ¸ë¥¼ ê²€ì‚¬í•´ í˜•ì‹ë³„ë¡œ ì•ˆì „í•˜ê²Œ ì½ëŠ”ë‹¤.
    ì§€ì›: HTML(UTF-8/CP949/EUC-KR), XLS(legacy), XLSX, CSV
    """
    b = file_bytes
    head = b[:64].lstrip()

    # 1) XLSX (ZIP ì‹œê·¸ë‹ˆì²˜: PK)
    if head.startswith(b"PK"):
        return pd.read_excel(io.BytesIO(b), engine="openpyxl")

    # 2) Legacy XLS (OLE2 ì‹œê·¸ë‹ˆì²˜: D0 CF 11 E0 A1 B1 1A E1)
    if head.startswith(b"\xD0\xCF\x11\xE0"):
        # xlrdëŠ” xlsë§Œ ì§€ì›
        return pd.read_excel(io.BytesIO(b), engine="xlrd")

    # 3) HTML (.xlsì´ì§€ë§Œ ì‚¬ì‹¤ HTML í…Œì´ë¸”ì¸ ê²½ìš°)
    if head.startswith(b"<!DOCTYPE") or head.startswith(b"<html") or b"<table" in b[:4096].lower():
        # ì¸ì½”ë”© ì¶”ì • ì—†ì´ ìˆœì°¨ ì‹œë„ (ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ ì²˜ë¦¬)
        for enc in ["utf-8", "cp949", "euc-kr"]:
            try:
                text = b.decode(enc, errors="strict")
                tables = pd.read_html(io.StringIO(text), flavor="lxml")
                if len(tables):
                    return tables[0]
            except Exception:
                continue
        # ëŠìŠ¨ ëª¨ë“œ(ê¹¨ì§„ ê¸€ìëŠ” ë¬´ì‹œ)
        try:
            text = b.decode("cp949", errors="ignore")
            tables = pd.read_html(io.StringIO(text), flavor="lxml")
            if len(tables):
                return tables[0]
        except Exception as e:
            raise RuntimeError(f"HTML í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨(lxml, ì¸ì½”ë”©): {e}")

    # 4) CSV ê°€ëŠ¥ì„± (ì‰¼í‘œ/íƒ­ ìë™ ì¶”ì •)
    try:
        return pd.read_csv(io.BytesIO(b))
    except Exception:
        pass
    try:
        return pd.read_csv(io.BytesIO(b), sep="\t")
    except Exception:
        pass

    raise RuntimeError(
        f"ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ì…ë‹ˆë‹¤. íŒŒì¼ëª…: {filename} (ì„ ë‘ ë°”ì´íŠ¸: {head[:16]!r})"
    )

def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).strip() for c in df.columns]
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

    def find_col(cols, keywords):
        for c in cols:
            lc = c.lower()
            if any(k in lc for k in keywords):
                return c
        return None

    cols = df.columns.tolist()
    col_time_utc = find_col(cols, ["ë°œìƒì¼ì‹œ(utc)", "utc"])
    col_time_kst = find_col(cols, ["ë°œìƒì¼ì‹œ(kst)", "kst"])
    col_time_any = find_col(cols, ["ë°œìƒì¼ì‹œ", "date", "time", "ì¼ì‹œ"])
    col_lat = find_col(cols, ["ìœ„ë„", "latitude", "lat"])
    col_lon = find_col(cols, ["ê²½ë„", "longitude", "lon"])
    col_depth = find_col(cols, ["ê¹Šì´", "depth"])
    col_mag = find_col(cols, ["ê·œëª¨", "magnitude", "mag"])
    col_place = find_col(cols, ["ìœ„ì¹˜", "ì§€ì—­", "ì¥ì†Œ", "place", "location"])
    col_remark = find_col(cols, ["ë¹„ê³ ", "remark", "ì°¸ê³ "])

    out = pd.DataFrame()
    time_col = col_time_utc or col_time_kst or col_time_any
    if time_col:
        out["time"] = pd.to_datetime(df[time_col], errors="coerce")

    def to_num(s):
        return pd.to_numeric(pd.Series(s).astype(str).str.replace(",", ""), errors="coerce")

    if col_lat:   out["latitude"]  = to_num(df[col_lat])
    if col_lon:   out["longitude"] = to_num(df[col_lon])
    if col_depth: out["depth_km"]  = to_num(df[col_depth])
    if col_mag:   out["magnitude"] = to_num(df[col_mag])
    if col_place: out["place"]     = df[col_place].astype(str)
    if col_remark:out["remark"]    = df[col_remark].astype(str)

    if "latitude" in out and "longitude" in out:
        out = out[(out["latitude"].between(-90, 90)) & (out["longitude"].between(-180, 180))]
    if "time" in out:
        out = out.sort_values("time").reset_index(drop=True)
    return out

# --------------------
# íŒŒì¼ ì…ë ¥
# --------------------
left, right = st.columns([1, 1])
with left:
    st.subheader("ğŸ“ ë°ì´í„° ì„ íƒ")
    up = st.file_uploader("êµ­ì™¸ì§€ì§„ëª©ë¡ íŒŒì¼ ì—…ë¡œë“œ (.xls, .xlsx, .html, .htm, .csv)", type=["xls", "xlsx", "html", "htm", "csv"])
    use_default = st.toggle(f"ê¸°ë³¸ íŒŒì¼ëª… ì‚¬ìš©: `{DEFAULT_FILE}`", value=True)

# ë°ì´í„° ì½ê¸°
df_raw = None
if up is not None:
    try:
        buf = up.read()
        df_raw = load_quakes(buf, filename=up.name)
    except Exception as e:
        st.error("íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.exception(e)
else:
    if use_default and Path(DEFAULT_FILE).exists():
        try:
            with open(DEFAULT_FILE, "rb") as f:
                df_raw = load_quakes(f.read(), filename=DEFAULT_FILE)
        except Exception as e:
            st.error("ê¸°ë³¸ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.exception(e)
    elif use_default:
        st.info(f"ê¸°ë³¸ íŒŒì¼ `{DEFAULT_FILE}` ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

if df_raw is not None and not df_raw.empty:
    df = clean_dataframe(df_raw)

    if df.empty or {"latitude", "longitude"}.issubset(df.columns) is False:
        st.error("ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ì„ í•´ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ í…Œì´ë¸”ì˜ ìœ„ë„/ê²½ë„ í‘œê¸°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # -------- ì‚¬ì´ë“œë°” í•„í„° --------
    with st.sidebar:
        st.header("ğŸ§­ í•„í„°")
        if "time" in df.columns and df["time"].notna().any():
            tmin = pd.to_datetime(df["time"].min())
            tmax = pd.to_datetime(df["time"].max())
            date_range = st.date_input("ê¸°ê°„ ì„ íƒ",
                value=(tmin.date(), tmax.date()),
                min_value=tmin.date(), max_value=tmax.date()
            )
        else:
            date_range = None

        if "magnitude" in df.columns and df["magnitude"].notna().any():
            mag_min = float(np.nanmin(df["magnitude"]))
            mag_max = float(np.nanmax(df["magnitude"]))
            m_lo, m_hi = st.slider("ê·œëª¨(M) ë²”ìœ„",
                min_value=float(np.floor(mag_min)),
                max_value=float(np.ceil(mag_max)),
                value=(float(np.floor(mag_min)), float(np.ceil(mag_max))),
                step=0.1
            )
        else:
            m_lo, m_hi = None, None

        if "depth_km" in df.columns and df["depth_km"].notna().any():
            dmin = float(np.nanmin(df["depth_km"]))
            dmax = float(np.nanmax(df["depth_km"]))
            dep_lo, dep_hi = st.slider("ê¹Šì´(km) ë²”ìœ„",
                min_value=float(max(0.0, np.floor(dmin))),
                max_value=float(np.ceil(dmax)),
                value=(float(max(0.0, np.floor(dmin))), float(np.ceil(dmax))),
                step=1.0
            )
        else:
            dep_lo, dep_hi = None, None

        place_query = st.text_input("ì§€ì—­/ìœ„ì¹˜ í‚¤ì›Œë“œ ğŸ”", value="").strip()

    # -------- í•„í„° ì ìš© --------
    df_f = df.copy()
    if date_range and "time" in df_f.columns and df_f["time"].notna().any():
        start_dt = pd.to_datetime(pd.Timestamp(date_range[0]))
        end_dt = pd.to_datetime(pd.Timestamp(date_range[1])) + pd.Timedelta(days=1)
        df_f = df_f[(df_f["time"] >= start_dt) & (df_f["time"] < end_dt)]
    if m_lo is not None and m_hi is not None and "magnitude" in df_f.columns:
        df_f = df_f[df_f["magnitude"].between(m_lo, m_hi)]
    if dep_lo is not None and dep_hi is not None and "depth_km" in df_f.columns:
        df_f = df_f[df_f["depth_km"].between(dep_lo, dep_hi)]
    if place_query and "place" in df_f.columns:
        df_f = df_f[df_f["place"].str.contains(place_query, case=False, na=False)]

    # -------- ê·œëª¨ ì •ìˆ˜ êµ¬ê°„ ë¼ë²¨ & ìƒ‰ìƒ --------
    if "magnitude" in df_f.columns and df_f["magnitude"].notna().any():
        mag_floor = np.floor(df_f["magnitude"]).astype("Int64")
        df_f["mag_bin_label"] = mag_floor.map(lambda v: f"{int(v)}.0â€“{int(v)}.9" if pd.notna(v) else np.nan)
        unique_bins = sorted(mag_floor.dropna().unique().tolist())
        labels_order = [f"{int(v)}.0â€“{int(v)}.9" for v in unique_bins]

        base_scale = px.colors.sequential.Bluered  # íŒŒë‘â†’ë¹¨ê°•
        def pick_color(pos):
            idx = int(round(pos * (len(base_scale) - 1)))
            return base_scale[idx]
        positions = np.linspace(0, 1, num=len(labels_order)) if labels_order else []
        color_list = [pick_color(p) for p in positions]
        color_map = {label: color_list[i] for i, label in enumerate(labels_order)}
    else:
        df_f["mag_bin_label"] = np.nan
        labels_order, color_map = [], {}

    # -------- KPI --------
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("í‘œì‹œ ê±´ìˆ˜", f"{len(df_f):,}")
    if "magnitude" in df_f.columns and df_f["magnitude"].notna().any():
        k2.metric("í‰ê·  ê·œëª¨", f"{df_f['magnitude'].mean():.2f}")
        k3.metric("ìµœëŒ€ ê·œëª¨", f"{df_f['magnitude'].max():.1f}")
    else:
        k2.metric("í‰ê·  ê·œëª¨", "-")
        k3.metric("ìµœëŒ€ ê·œëª¨", "-")
    if "depth_km" in df_f.columns and df_f["depth_km"].notna().any():
        k4.metric("í‰ê·  ê¹Šì´(km)", f"{df_f['depth_km'].mean():.0f}")
    else:
        k4.metric("í‰ê·  ê¹Šì´(km)", "-")

    # -------- ì§€ë„ --------
    st.subheader("ğŸŒ ê·œëª¨ ì •ìˆ˜ êµ¬ê°„ë³„ ìƒ‰ìƒ ì§€ì§„ ì§€ë„")
    hover_cols = []
    if "time" in df_f.columns: hover_cols.append("time")
    if "place" in df_f.columns: hover_cols.append("place")
    if "depth_km" in df_f.columns: hover_cols.append("depth_km")
    if "magnitude" in df_f.columns: hover_cols.append("magnitude")
    size_col = "magnitude" if "magnitude" in df_f.columns else None

    fig = px.scatter_geo(
        df_f,
        lat="latitude",
        lon="longitude",
        size=size_col,
        color="mag_bin_label",
        color_discrete_map=color_map,
        category_orders={"mag_bin_label": labels_order},
        size_max=16,
        opacity=0.8,
        hover_data=hover_cols,
        projection="natural earth",
    )
    fig.update_layout(margin=dict(l=0, r=0, t=0, b=0), legend_title_text="ê·œëª¨ êµ¬ê°„(M)")
    st.plotly_chart(fig, use_container_width=True)

    with st.expander("ğŸ“„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (í•„í„° ì ìš© í›„)"):
        st.dataframe(df_f.head(100), use_container_width=True)

else:
    st.info("ì™¼ìª½ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, ê¸°ë³¸ íŒŒì¼ì´ ìˆì„ ê²½ìš° í† ê¸€ì„ ì¼œì„œ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
