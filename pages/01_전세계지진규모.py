import io
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ğŸŒ ì „ì„¸ê³„ ì§€ì§„ ê·œëª¨ ì§€ë„", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ ì „ì„¸ê³„ ì§€ì§„ ê·œëª¨ ì§€ë„")
st.caption("ì •ìˆ˜ ê·œëª¨ êµ¬ê°„(0.0â€“0.9, â€¦, 9.0â€“9.9, 10.0)ê³¼ ì§„ì› ê¹Šì´ êµ¬ê°„ì„ í•œ ì§€ë„ì—ì„œ í™•ì¸í•©ë‹ˆë‹¤. (ê·œëª¨: ì‚´êµ¬â†’ì£¼í™©â†’ì ìƒ‰â†’ì•”ì ìƒ‰)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_coord(series: pd.Series, kind: str) -> pd.Series:
    s = series.astype(str).str.strip()
    num = pd.to_numeric(s.str.extract(r'([-+]?\d+(?:\.\d+)?)')[0], errors="coerce")
    if kind == "lat":
        return num.mask(s.str.contains(r"[Ss]"), -num)
    else:
        return num.mask(s.str.contains(r"[Ww]"), -num)

def to_num(series: pd.Series) -> pd.Series:
    return pd.to_numeric(series.astype(str).str.replace(",", ""), errors="coerce")

def make_mag_bin_label(m: pd.Series) -> pd.Series:
    mf = np.floor(m).astype("Int64").clip(lower=0, upper=10)
    def lab(v):
        if pd.isna(v): return np.nan
        v = int(v)
        return f"{v}.0â€“{v}.9" if v < 10 else "10.0"
    return mf.map(lab)

# â˜… ìƒˆ: íŒŒë‘ ì—†ëŠ” Warm ê·¸ë¼ë°ì´ì…˜ íŒ”ë ˆíŠ¸(ë°ì€ ì‚´êµ¬ â†’ í˜¸ë°• â†’ ì£¼í™© â†’ ì ìƒ‰ â†’ ì•”ì ìƒ‰)
WARM_SCALE = [
    (0.00, "#FFF3E0"),  # very light apricot
    (0.25, "#FFB300"),  # amber
    (0.45, "#FB8C00"),  # orange
    (0.70, "#E53935"),  # vivid red
    (0.88, "#B71C1C"),  # dark red
    (1.00, "#4A0C0C"),  # maroon
]

def build_mag_colors(labels_order):
    """ì •ìˆ˜ êµ¬ê°„ ë¼ë²¨(0~10)ì„ 0~1ë¡œ ì •ê·œí™”í•´ WARM_SCALEì—ì„œ ìƒ˜í”Œë§ â†’ êµ¬ê°„ë³„ ì´ì‚° ìƒ‰ìƒ"""
    if not labels_order:
        return {}
    def bin_index(label):  # '10.0'ì€ ìµœëŒ“ê°’ìœ¼ë¡œ
        return 10 if label == "10.0" else int(label.split(".")[0])
    # ë„ˆë¬´ ë°ì€ ìª½ì´ ëª°ë¦¬ì§€ ì•Šë„ë¡ ì‚´ì§ ê°ë§ˆ ë³´ì •(1.15)
    raw = np.array([bin_index(l) for l in labels_order], dtype=float) / 10.0
    pos = np.clip(raw**1.15, 0, 1).tolist()
    sampled = px.colors.sample_colorscale(WARM_SCALE, pos)
    return dict(zip(labels_order, sampled))

def depth_category(d: pd.Series) -> pd.Series:
    cat = pd.Series(index=d.index, dtype=object)
    cat[(d >= 0) & (d < 70)]     = "ì²œë°œ(0â€“70km)"
    cat[(d >= 70) & (d <= 300)]  = "ì¤‘ë°œ(70â€“300km)"
    cat[(d > 300)]               = "ì‹¬ë°œ(>300km)"
    return cat

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œë” (xlsx/xls/html/csv ìë™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def load_quakes(file_bytes: bytes, filename: str = "uploaded") -> pd.DataFrame:
    b = file_bytes or b""
    head = b[:64].lstrip()
    if head.startswith(b"PK"):  # XLSX
        return pd.read_excel(io.BytesIO(b), engine="openpyxl")
    if head.startswith(b"\xD0\xCF\x11\xE0"):  # XLS
        return pd.read_excel(io.BytesIO(b), engine="xlrd")
    looks_html = head.startswith(b"<!DOCTYPE") or head.startswith(b"<html") or (b"<table" in b[:8192].lower())
    if looks_html:
        for enc in ["utf-8", "cp949", "euc-kr"]:
            try:
                text = b.decode(enc, errors="strict")
                for flavor in ["html5lib", "lxml"]:
                    try:
                        tables = pd.read_html(io.StringIO(text), flavor=flavor)
                        if len(tables):
                            return tables[0]
                    except Exception:
                        pass
            except Exception:
                pass
        try:
            from bs4 import BeautifulSoup
            text = b.decode("cp949", errors="ignore")
            soup = BeautifulSoup(text, "html.parser")
            table = soup.find("table")
            if table:
                tables = pd.read_html(io.StringIO(str(table)), flavor="lxml")
                if len(tables):
                    return tables[0]
        except Exception:
            pass
        raise RuntimeError("HTML í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (html5lib/lxml/bs4 ëª¨ë‘ ì‹¤íŒ¨)")
    for kwargs in [dict(), dict(sep="\t"), dict(sep=";")]:
        try:
            return pd.read_csv(io.BytesIO(b), **kwargs)
        except Exception:
            pass
    raise RuntimeError(f"ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {filename}")

def auto_clean(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()
    df.columns = [str(c).strip() for c in df.columns]
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    def find_col(cols, keys):
        for c in cols:
            lc = c.lower()
            if any(k in lc for k in keys): return c
        return None
    cols = df.columns.tolist()
    col_time = find_col(cols, ["ë°œìƒì‹œê°", "ë°œìƒì¼ì‹œ", "date", "time", "ì¼ì‹œ"])
    col_mag  = find_col(cols, ["ê·œëª¨", "magnitude", "mag"])
    col_dep  = find_col(cols, ["ê¹Šì´", "depth"])
    col_lat  = find_col(cols, ["ìœ„ë„", "latitude", "lat"])
    col_lon  = find_col(cols, ["ê²½ë„", "longitude", "lon", "lng"])
    col_place= find_col(cols, ["ìœ„ì¹˜", "ì§€ì—­", "ì¥ì†Œ", "place", "location"])

    out = pd.DataFrame()
    if col_time:         out["time"]      = pd.to_datetime(df[col_time], errors="coerce")
    if col_mag:          out["magnitude"] = to_num(df[col_mag])
    if col_dep:          out["depth_km"]  = to_num(df[col_dep])
    if col_lat:          out["latitude"]  = parse_coord(df[col_lat], "lat")
    if col_lon:          out["longitude"] = parse_coord(df[col_lon], "lon")
    if col_place:        out["place"]     = df[col_place].astype(str)

    if {"latitude","longitude"}.issubset(out.columns):
        out = out[(out["latitude"].between(-90, 90)) & (out["longitude"].between(-180, 180))]
    if "time" in out.columns:
        out = out.sort_values("time").reset_index(drop=True)
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì…ë ¥ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
left, right = st.columns([1,1])
with left:
    st.subheader("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")
    up = st.file_uploader("êµ­ì™¸ì§€ì§„ëª©ë¡ íŒŒì¼(.xlsx, .xls, .html, .htm, .csv)", type=["xlsx","xls","html","htm","csv"])
with right:
    st.subheader("ğŸ§ª í‘œì‹œ ëª¨ë“œ")
    show_mag   = st.toggle("ê·œëª¨ í™•ì¸ (ì›, êµ¬ê°„ë³„-ê·¸ë¼ë°ì´ì…˜ ìƒ‰)", value=True)
    show_depth = st.toggle("ê¹Šì´ í™•ì¸ (ì‚¼ê°í˜•, ì²œÂ·ì¤‘Â·ì‹¬ë°œ ìƒ‰)", value=False)

if up is None:
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. (ì˜ˆ: êµ­ì™¸ì§€ì§„ëª©ë¡_5ê°œë…„.xlsx)")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œë“œ & ì •ì œ (+ í•„ìš”ì‹œ ìˆ˜ë™ ë§¤í•‘)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    raw = load_quakes(up.read(), filename=up.name)
except Exception as e:
    st.error("íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    st.exception(e)
    st.stop()

clean = auto_clean(raw)
if not {"latitude","longitude"}.issubset(clean.columns):
    st.warning("ìë™ ìœ„ë„/ê²½ë„ íƒì§€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì»¬ëŸ¼ì„ ì§ì ‘ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    cols = list(raw.columns)
    c1, c2, c3, c4, c5 = st.columns(5)
    with c1: lat_col = st.selectbox("ìœ„ë„", cols, index=None, placeholder="ì„ íƒ")
    with c2: lon_col = st.selectbox("ê²½ë„", cols, index=None, placeholder="ì„ íƒ")
    with c3: mag_col = st.selectbox("ê·œëª¨(ì„ íƒ)", [None]+cols, index=0)
    with c4: dep_col = st.selectbox("ê¹Šì´(ì„ íƒ)", [None]+cols, index=0)
    with c5: time_col = st.selectbox("ì‹œê°„(ì„ íƒ)", [None]+cols, index=0)

    clean = pd.DataFrame()
    if time_col: clean["time"] = pd.to_datetime(raw[time_col], errors="coerce")
    if mag_col:  clean["magnitude"] = to_num(raw[mag_col])
    if dep_col:  clean["depth_km"] = to_num(raw[dep_col])
    if lat_col:  clean["latitude"] = parse_coord(raw[lat_col], "lat")
    if lon_col:  clean["longitude"] = parse_coord(raw[lon_col], "lon")
    if {"latitude","longitude"}.issubset(clean.columns):
        clean = clean[(clean["latitude"].between(-90,90)) & (clean["longitude"].between(-180,180))]
        if "time" in clean: clean = clean.sort_values("time").reset_index(drop=True)
    else:
        st.error("ìœ„ë„/ê²½ë„ëŠ” ë°˜ë“œì‹œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°” í•„í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ğŸ§­ í•„í„°")
    if "time" in clean.columns and clean["time"].notna().any():
        tmin, tmax = pd.to_datetime(clean["time"].min()), pd.to_datetime(clean["time"].max())
        date_range = st.date_input("ê¸°ê°„", value=(tmin.date(), tmax.date()),
                                   min_value=tmin.date(), max_value=tmax.date())
    else:
        date_range = None
    if "magnitude" in clean.columns and clean["magnitude"].notna().any():
        mag_min, mag_max = float(np.nanmin(clean["magnitude"])), float(np.nanmax(clean["magnitude"]))
        m_lo, m_hi = st.slider("ê·œëª¨(M)", min_value=float(np.floor(mag_min)),
                               max_value=float(np.ceil(mag_max)),
                               value=(float(np.floor(mag_min)), float(np.ceil(mag_max))), step=0.1)
    else:
        m_lo, m_hi = None, None
    if "depth_km" in clean.columns and clean["depth_km"].notna().any():
        dmin, dmax = float(np.nanmin(clean["depth_km"])), float(np.nanmax(clean["depth_km"]))
        dep_lo, dep_hi = st.slider("ê¹Šì´(km)", min_value=float(max(0.0, np.floor(dmin))),
                                   max_value=float(np.ceil(dmax)),
                                   value=(float(max(0.0, np.floor(dmin))), float(np.ceil(dmax))), step=1.0)
    else:
        dep_lo, dep_hi = None, None
    place_query = st.text_input("ì§€ì—­/ìœ„ì¹˜ í‚¤ì›Œë“œ ğŸ”", value="").strip()

f = clean.copy()
if date_range and "time" in f.columns and f["time"].notna().any():
    start_dt = pd.to_datetime(pd.Timestamp(date_range[0]))
    end_dt   = pd.to_datetime(pd.Timestamp(date_range[1])) + pd.Timedelta(days=1)
    f = f[(f["time"] >= start_dt) & (f["time"] < end_dt)]
if m_lo is not None and m_hi is not None and "magnitude" in f.columns:
    f = f[f["magnitude"].between(m_lo, m_hi)]
if dep_lo is not None and dep_hi is not None and "depth_km" in f.columns:
    f = f[f["depth_km"].between(dep_lo, dep_hi)]
if place_query and "place" in f.columns:
    f = f[f["place"].str.contains(place_query, case=False, na=False)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë ˆì´ì–´ ì¤€ë¹„ ë° ë Œë”ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
traces = []

# (A) ê·œëª¨ ë ˆì´ì–´: Non-Blue ê·¸ë¼ë°ì´ì…˜ì—ì„œ êµ¬ê°„ë³„ ìƒ‰ ìƒ˜í”Œë§
if show_mag and "magnitude" in f.columns and f["magnitude"].notna().any():
    f_mag = f.copy()
    f_mag["mag_bin"] = make_mag_bin_label(f_mag["magnitude"])
    order_all = [f"{i}.0â€“{i}.9" for i in range(0,10)] + ["10.0"]
    labels_order = [lab for lab in order_all if lab in set(f_mag["mag_bin"].dropna().unique())]
    mag_color_map = build_mag_colors(labels_order)

    for lab in labels_order:
        dfb = f_mag[f_mag["mag_bin"] == lab]
        if dfb.empty:
            continue
        size_vals = np.clip((dfb["magnitude"].fillna(dfb["magnitude"].median()) * 2.0), 5, 22)
        traces.append(go.Scattergeo(
            lon=dfb["longitude"], lat=dfb["latitude"],
            mode="markers",
            name=f"ê·œëª¨ {lab}",
            legendgroup="magnitude", showlegend=True,
            marker=dict(
                symbol="circle",
                size=size_vals,
                color=mag_color_map[lab],
                line=dict(width=0.7, color="white"),
                opacity=0.95,
            ),
            hovertemplate="<b>ê·œëª¨(M)</b>: %{customdata[0]:.1f}<br>"
                          "ìœ„ë„: %{lat:.2f}, ê²½ë„: %{lon:.2f}<br>"
                          "%{customdata[1]}",
            customdata=np.stack([
                dfb["magnitude"].values if "magnitude" in dfb else np.full(len(dfb), np.nan),
                dfb["place"].values if "place" in dfb else np.array([""]*len(dfb))
            ], axis=1)
        ))

# (B) ê¹Šì´ ë ˆì´ì–´: ê·¸ëŒ€ë¡œ ìœ ì§€(í•˜ëŠ˜/íŒŒë‘/ì§™ì€ íŒŒë‘)
if show_depth and "depth_km" in f.columns and f["depth_km"].notna().any():
    f_dep = f.copy()
    f_dep["depth_cat"] = depth_category(f_dep["depth_km"])
    depth_order = ["ì²œë°œ(0â€“70km)", "ì¤‘ë°œ(70â€“300km)", "ì‹¬ë°œ(>300km)"]
    depth_colors = {
        "ì²œë°œ(0â€“70km)": "#87CEEB",  # í•˜ëŠ˜ìƒ‰
        "ì¤‘ë°œ(70â€“300km)": "#1976D2", # íŒŒë€ìƒ‰
        "ì‹¬ë°œ(>300km)": "#0D47A1",  # ì–´ë‘ìš´ í‘¸ë¥¸ìƒ‰
    }
    for lab in depth_order:
        dfd = f_dep[f_dep["depth_cat"] == lab]
        if dfd.empty:
            continue
        traces.append(go.Scattergeo(
            lon=dfd["longitude"], lat=dfd["latitude"],
            mode="markers",
            name=f"ê¹Šì´ {lab}",
            legendgroup="depth", showlegend=True,
            marker=dict(
                symbol="triangle-up",
                size=11,
                color=depth_colors[lab],
                line=dict(width=0.5, color="white"),
                opacity=0.95,
            ),
            hovertemplate="<b>ê¹Šì´</b>: %{customdata[0]} km<br>"
                          "ìœ„ë„: %{lat:.2f}, ê²½ë„: %{lon:.2f}<br>"
                          "%{customdata[1]}",
            customdata=np.stack([
                dfd["depth_km"].round(0).astype("Int64").astype(str).replace("<NA>","-").values
                    if "depth_km" in dfd else np.array(["-"]*len(dfd)),
                dfd["place"].values if "place" in dfd else np.array([""]*len(dfd))
            ], axis=1)
        ))

if not traces:
    st.info("ì˜¤ë¥¸ìª½ ìƒë‹¨ì˜ í† ê¸€(ê·œëª¨ í™•ì¸ / ê¹Šì´ í™•ì¸)ì„ ì¼œê³  ì§€ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
else:
    fig = go.Figure(data=traces)
    fig.update_layout(
        geo=dict(projection=dict(type="natural earth"), showcountries=True),
        margin=dict(l=0, r=0, t=0, b=0),
        legend=dict(title="ë ˆì´ì–´", orientation="h", yanchor="bottom", y=0.02, xanchor="left", x=0.02)
    )
    st.plotly_chart(fig, use_container_width=True)

with st.expander("ğŸ“„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (í•„í„° ì ìš© í›„)"):
    show_cols = [c for c in ["time","magnitude","depth_km","place","latitude","longitude"] if c in f.columns]
    st.dataframe(f[show_cols].head(100), use_container_width=True)
